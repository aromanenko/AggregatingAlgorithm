{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba5efd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.forecasting.theta import ThetaModel\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.special import rel_entr, kl_div\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95dc2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_density_forecast(ts, horizon, base_alg, base_params={}, bins='auto', omega=None, fittedvalues=False):\n",
    "    \"\"\"\n",
    "    Returns a list of density dictionaries {'bins': np.array, 'probs': np.array, 'dotted_forecast': float}.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ts : array_like\n",
    "        The time series to model.\n",
    "    horizon : int\n",
    "        The horizon to forecast.\n",
    "    base_alg : {ExponentialSmoothing, SimpleExpSmoothing, Holt}\n",
    "        The name of base algoritm for making density forecast.\n",
    "    base_params : dict\n",
    "        A Dictionary with base algorithm parameters.\n",
    "    bins: int or sequence of scalars or str, optional\n",
    "        Define how to calculate bins.\n",
    "    fittedvalues: bool\n",
    "        Include fitted values in density dictionaries or not.\n",
    "    \"\"\"\n",
    "    \n",
    "    if omega is not None:\n",
    "        bins = omega\n",
    "    \n",
    "    alg = base_alg(ts, **base_params).fit()\n",
    "    \n",
    "    if fittedvalues:\n",
    "        alg_preds = alg.predict(start=0, end=len(ts) + horizon - 1)\n",
    "        density_dicts = [{'bins': [], 'probs': [], 'dotted_forecast': None} for _ in range(len(ts) + horizon)]\n",
    "    else:\n",
    "        alg_preds = alg.predict(start=len(ts), end=len(ts) + horizon - 1)\n",
    "        density_dicts = [{'bins': [], 'probs': [], 'dotted_forecast': None} for _ in range(horizon)]\n",
    "    \n",
    "    for i in range(len(alg_preds)):\n",
    "        density_dicts[i]['dotted_forecast'] = alg_preds.iloc[i]\n",
    "        \n",
    "        current_density = alg.resid + alg_preds.iloc[i]\n",
    "        probs, bins = np.histogram(current_density, bins=bins)\n",
    "        density_dicts[i]['probs'], density_dicts[i]['bins'] = probs / np.sum(probs), bins\n",
    "    \n",
    "    return density_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f584a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density_forecast(ts, delay, base_alg, ax=None, **kwargs):\n",
    "        \n",
    "    density_dict = get_density_forecast(ts, delay, base_alg, **kwargs)[delay - 1]\n",
    "\n",
    "    left_edges = density_dict['bins'][:-1]\n",
    "\n",
    "    colors = []\n",
    "    for i in range(len(left_edges) - 1):\n",
    "        if left_edges[i] < density_dict['dotted_forecast'] < left_edges[i+1]:\n",
    "            colors.append('coral')\n",
    "        else:\n",
    "            colors.append('royalblue')\n",
    "    \n",
    "    alg_name = str(base_alg)[str(base_alg).find('model.') + 6:-2]\n",
    "    \n",
    "    if ax:\n",
    "        ax.bar(left_edges, density_dict['probs'], align='edge',\n",
    "               width=0.9*(left_edges[1] - left_edges[0]), color=colors)\n",
    "        ax.set_title(f'{alg_name}: density forecast with delay={delay}')\n",
    "    else:\n",
    "        plt.bar(left_edges, density_dict['probs'], align='edge',\n",
    "               width=0.9*(left_edges[1] - left_edges[0]), color=colors)\n",
    "        plt.title(f'{alg_name}: density forecast with delay={delay}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b8b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omega(ts, mode, bins=None, quantile=0.1):\n",
    "    if mode == \"basic\":\n",
    "        return np.histogram_bin_edges(ts, bins)\n",
    "    if mode == \"quantile\":\n",
    "        bin_width = int(np.quantile(abs(ts - ts.shift(1))[1:], quantile))\n",
    "    elif mode == \"mean\":\n",
    "        bin_width = int(np.mean(abs(ts - ts.shift(1))[1:]))\n",
    "    \n",
    "    if bin_width < 1:\n",
    "        bin_width = 1\n",
    "    \n",
    "    min_o = int(np.floor(min(ts.values)))\n",
    "    max_o = int(np.ceil(max(ts.values)))\n",
    "    \n",
    "    bin_edges = [min_o]\n",
    "    while bin_edges[-1] < max_o:\n",
    "        bin_edges.append(bin_edges[-1] + bin_width)\n",
    "    \n",
    "    return np.array(bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5898050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_loss(y_true, density_dict, p=2):\n",
    "    \"\"\"\n",
    "    Returns np.array of brier scores.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : float\n",
    "        A true value.\n",
    "    density_dict : dict\n",
    "        Dict with bins and probabilities information.\n",
    "    \"\"\"\n",
    "    bins_number = density_dict['probs'].size\n",
    "    bins_true = [0] * bins_number\n",
    "\n",
    "    for i in range(bins_number):\n",
    "        if (density_dict['bins'][i] <= y_true <= density_dict['bins'][i + 1]):\n",
    "            bins_true[i] = 1\n",
    "            break\n",
    "    \n",
    "    brier_loss = np.sum((abs(density_dict['probs'] - bins_true))**p)\n",
    "    \n",
    "    if np.sum(bins_true) == 0:\n",
    "        brier_loss += 1\n",
    "        \n",
    "    return brier_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8dfcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generalized_loss(y_true, density_dicts, loss_function, p):\n",
    "    \"\"\"\n",
    "    Returns np.array of brier scores.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : float\n",
    "        A true value.\n",
    "    density_dicts : dict or array-like of dicts\n",
    "        Dicts with bins and probabilities information.\n",
    "    \"\"\"\n",
    "    if type(density_dicts) == dict:\n",
    "        density_dicts = [density_dicts]\n",
    "    \n",
    "    losses = [np.nan] * len(density_dicts)\n",
    "    \n",
    "    for density_dict_count, density_dict in enumerate(density_dicts):\n",
    "        losses[density_dict_count] = loss_function(y_true, density_dict, p)\n",
    "    \n",
    "    return np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987b50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoid_overflowing(base, power_array):\n",
    "    maximum = np.max(power_array)\n",
    "    minimum = np.min(power_array)\n",
    "    \n",
    "    pmax = -np.log(base)/np.log(2) * maximum\n",
    "    pmin = -np.log(base)/np.log(2) * minimum\n",
    "    \n",
    "    if np.abs(pmax-pmin) > 2097:\n",
    "        print('Overflow is imminent. Further calculations are not advised')\n",
    "        return base ** power_array\n",
    "    power_shift = abs((51+pmin+pmax)/2)\n",
    "    power_shift = power_shift + min(0, pmin - power_shift + 1023)\n",
    "    \n",
    "    power_array = power_array - np.abs(power_shift * np.log(2) / np.log(base))\n",
    "    \n",
    "    return base ** power_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c891fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generalized_prediction(ts, preds, omega, weights, loss_function, p, eta):\n",
    "    generalized_predictions = []\n",
    "    \n",
    "    for w in zip(omega, omega[1:]):\n",
    "        losses = get_generalized_loss((w[0] + w[1]) / 2, preds, loss_function, p)\n",
    "        exp_losses = avoid_overflowing(np.e, -eta * losses)\n",
    "        generalized_predictions.append(-(1 / eta) * np.log(np.sum(weights * exp_losses)))\n",
    "        \n",
    "    return np.array(generalized_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33b19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "def s_equation(s, generalized_predictions, m=2):\n",
    "    return np.sum([max(x,0) for x in s - generalized_predictions]) - m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "218c9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitution_function(generalized_predictions, s, m=2):\n",
    "    predictions = [max(x,0) / m for x in (s - generalized_predictions)]\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9236fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_AA_density(omega_and_predictions, bins):\n",
    "#     probs = [0] * (len(bins) - 1)\n",
    "#     for i in range(len(bins) - 1):\n",
    "#         for omega, pred in omega_and_predictions:\n",
    "#             if bins[i] <= omega < bins[i + 1]:\n",
    "#                 probs[i] += pred\n",
    "#     return np.array(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c4326a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, losses, eta=1):\n",
    "    exp_losses = avoid_overflowing(np.e, -eta * np.array(losses))\n",
    "    new_weights = weights * exp_losses\n",
    "    return new_weights / (np.sum(new_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4bb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregating_algorithm(ts, horizon, base_alg_dict, bins=10, omega_mode=\"basic\",\n",
    "                          loss_function=brier_loss, p=2, weights=None, eta=1):\n",
    "    \"\"\"\n",
    "    Returns density dictionary {'bins': np.array, 'probs': np.array, 'dotted_forecast': float}.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ts : array_like\n",
    "        The time series to model.\n",
    "    delay : int\n",
    "        The delay to forecast.\n",
    "    base_alg_dict : dict\n",
    "        The dictionary with the names of base algoritms and their params:\n",
    "        base_alg {ExponentialSmoothing, SimpleExpSmoothing, Holt} - name of base algorithm.\n",
    "        base_alg_params : dict - a dictionary of base algorithm's parameters.\n",
    "    loss_function : function\n",
    "        The loss function of aggregating algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    T = len(ts)\n",
    "    K = len(base_alg_dict)\n",
    "    \n",
    "    AA_preds = [{} for i in range(T + horizon)]\n",
    "    BA_preds = np.array([{} for i in range((T + horizon) * K)]).reshape(K, T + horizon) \n",
    "    \n",
    "    if not weights:\n",
    "        weights = np.full(K, 1/K)\n",
    "    \n",
    "    omega = get_omega(ts, mode=omega_mode, bins=bins) # здесь в Omega прогнозы не учитываются\n",
    " \n",
    "    i = 0\n",
    "    for base_alg, base_alg_params in base_alg_dict.items():\n",
    "        BA_preds[i] = get_density_forecast(ts, horizon, base_alg, base_params=base_alg_params,\n",
    "                                           omega=omega, fittedvalues=True)\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "    losses, prev_losses = None, None\n",
    "        \n",
    "    for t in tqdm(range(T + horizon)):\n",
    "        preds = BA_preds[:, t]\n",
    "        \n",
    "        if not prev_losses:\n",
    "            prev_losses = [loss_function(ts.values[t], pred, p) for pred in preds]  # cheat\n",
    "              \n",
    "        generalized_predictions = get_generalized_prediction(ts.values[:t], preds, omega,\n",
    "                                                             weights, loss_function, p, eta)\n",
    "        \n",
    "        #solving the equation to find s\n",
    "        s_init = np.max(generalized_predictions)\n",
    "        s = fsolve(s_equation, s_init, args=generalized_predictions)\n",
    "        \n",
    "        #get real prediction with substitution function\n",
    "        AA_preds[t]['bins'] = BA_preds[:, t][0]['bins']\n",
    "        real_predictions = substitution_function(generalized_predictions, s)\n",
    "        AA_preds[t]['probs'] = real_predictions\n",
    "        \n",
    "        #update weights \n",
    "        if t < T:            \n",
    "            losses = [loss_function(ts.values[t], pred, p) for pred in preds]\n",
    "            weights = update_weights(weights, losses, eta)\n",
    "\n",
    "            prev_losses = losses\n",
    "    \n",
    "    return AA_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
